{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is Recommender System**\n",
    "\n",
    "- A system that predicts ratings or preferences a user might give to an item\n",
    "- Often these are sorted and presented as \"top-N\" recommendtions\n",
    "- Also known as recommender engines, recommendation systems, recommendation platforms\n",
    "\n",
    "**Examples**\n",
    "\n",
    "- Amazon\n",
    "- Netflix\n",
    "- Amazon Prime\n",
    "- Google Search\n",
    "- Youtube\n",
    "\n",
    "**Understanding users is important**\n",
    "\n",
    "- *Asking for feedback (Explicit)*\n",
    "\n",
    "> Pros:  \n",
    "    >- More data\n",
    "\n",
    "> Cons:  \n",
    ">- Not a quality data\n",
    ">- Random data\n",
    ">- Not Standardised\n",
    "\n",
    "- *Implicit Data*\n",
    "\n",
    "> 1. Clicked\n",
    "\n",
    "\n",
    ">> Pros:  \n",
    ">> - Huge Data\n",
    "\n",
    ">> Cons:\n",
    ">>- Not a quality data\n",
    ">>- Not exact reflection\n",
    "\n",
    "> 2. Purchased\n",
    "\n",
    "\n",
    ">> Pros:  \n",
    ">> - Less Data\n",
    "\n",
    ">> Cons:\n",
    ">>- Very quality data\n",
    ">>- Exact reflection\n",
    "\n",
    "> 3. Consumed\n",
    "\n",
    "\n",
    ">> Pros:  \n",
    ">> - Good amount of data\n",
    "\n",
    ">> Cons:\n",
    ">>- Liitle quality data\n",
    ">>- Good reflection\n",
    "\n",
    "\n",
    "**Different Recommendation Systems**\n",
    "\n",
    "- Recommanding things -- Amazon\n",
    "- Recommanding Content -- Youtube, Netflix\n",
    "- Recommanding Music -- Raaga, Saavn\n",
    "- Recommanding People -- Facebook\n",
    "- Recommanding Search Results -- Google\n",
    "\n",
    "**Top N Recommendations**\n",
    "\n",
    "- Recommendation are ranked\n",
    "- Only Top N Recommendations used\n",
    "- Examples : Amazon and Netflix\n",
    "\n",
    "\n",
    "**Evaluting Recommender Systems**\n",
    "\n",
    "- Train - Test Model\n",
    "\n",
    "> Full data set (movie ratings, etc.)\n",
    "\n",
    ">> Training set  --> Machine learning  --> Predictions\n",
    "\n",
    ">> Test set --> Measure Accuracy --> Predictions\n",
    "\n",
    "\n",
    "- K-fold cross validation\n",
    "\n",
    "> Full data set (movie ratings, etc.)\n",
    "\n",
    ">> fold 1  --> machine learning  --> measure accuracy  --> take average\n",
    "\n",
    ">> fold 2  --> machine learning  --> measure accuracy  --> take average\n",
    "\n",
    ">> fold k-1  --> machine learning  --> measure accuracy  --> take average\n",
    "\n",
    ">> test set --> measure accuracy  --> take average\n",
    "\n",
    "\n",
    "**Measuring Accuracy**\n",
    "\n",
    "- Mean Absolute Error (MAE)\n",
    "\n",
    "$$MAE=\\sum_{i-1}^n \\frac{ |y_{i}-x_i|}{n}$$\n",
    "\n",
    "MAE - mean absolute error  \n",
    "$y_i$ - prediction  \n",
    "$x_i$ - true value  \n",
    "n   - total number of data points  \n",
    "\n",
    "\n",
    "| Predicted (y) | Actual (x) | Error |\n",
    "| --- | --- | --- |\n",
    "| 5| 4 | 1 |\n",
    "| 3| 5 | -2 |\n",
    "| 4| 4 | 0 |\n",
    "| 5| 3 | 2 |\n",
    "| 2| 3 | -1 |\n",
    "| 1| 2 | -1 |\n",
    "\n",
    "Mean Absolute Error - 1.166\n",
    "\n",
    "- Root Mean Square Error/Deviation (RMSE/RMSD)\n",
    "\n",
    "$$RMSD = \\sqrt{\\sum_{i-1}^N \\frac{ (x_{i}-\\hat x_i)^2}{N}}$$\n",
    "\n",
    "RMSD - root-mean square deviation  \n",
    "i    - variable i  \n",
    "N    - number of non-missing data points  \n",
    "$x_{i}$ - actual observation time series  \n",
    "$\\hat x_i$ - estimated time series\n",
    "\n",
    "| estimated (x) | Actual (x) | Error |\n",
    "| --- | --- | --- |\n",
    "| 5| 4 | 1 |\n",
    "| 3| 5 | -2 |\n",
    "| 4| 4 | 0 |\n",
    "| 5| 3 | 2 |\n",
    "| 2| 3 | -1 |\n",
    "| 1| 2 | -1 |\n",
    "\n",
    "Root Mean Square Error/Deviation = 1.354006\n",
    "\n",
    "**Top N Movies**\n",
    "\n",
    "- Only popular movies\n",
    "- Popular in particular condition\n",
    "- Min vote conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top N Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md=pd.read_csv('Dataset/movies_metadata.csv')\n",
    "md.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "md['genres']=md['genres'].fillna('[]')\n",
    "md.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval Example\n",
    "list1='[1,2,3,4,5]'\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_eval=eval(list1)\n",
    "list_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_eval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "literal_eval(list1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting genres as list\n",
    "md['genres']=md['genres'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md['genres']=md['genres'].apply(lambda x: [i['name'] for i in x] if isinstance(x,list) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md[md['vote_count'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_count=md[md['vote_count'].notnull()]['vote_count'].astype('int')\n",
    "vote_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_average=md[md['vote_average'].notnull()]['vote_average'].astype('int')\n",
    "vote_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommending top movies\n",
    "top_movies=md.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting in order of vote average\n",
    "top_movies1=top_movies.sort_values('vote_average',ascending=False).head(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min number of votes 1000\n",
    "top_movies2=top_movies[top_movies['vote_count']>1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies2.sort_values('vote_average',ascending=False).head(250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weighted Rating**\n",
    "\n",
    "\n",
    "$$W=\\frac{R - v + C - m}{v + m}$$\n",
    "\n",
    "where:  \n",
    "\n",
    "- $W$ = Weighted rating\n",
    "- $R$ = average for the movies as a number from 1 to 10 (mean) = (Rating)\n",
    "- $v$ = number of votes for the movie = (votes)\n",
    "- $m$ = minimum votes required to be listed in the Top 250 (currently 25,000)\n",
    "- $C$ = the mean vote across the whole report (currently 7 0)\n",
    "\n",
    "The $W$ in this formula is equivalent to a Bayesian posterior mean (see *Bayesian statistics*)\n",
    "\n",
    "1. The next step is to determine an appropriate value of m, the minimum votes required to be listed in the chart. We will use **95 percentile** or Median as our cutoff. In other words, for a movie to feature in the charts. It must have more votes than at least 95% of the movies in the list\n",
    "2. We will calculate C value as average votes across the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=vote_average.mean()\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = vote_count.quantile(0.95)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies['year']=pd.to_datetime(top_movies['release_date'],errors='coerce').apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies3=top_movies[(top_movies['vote_count']>=m) & (top_movies['vote_count'].notnull()) & (top_movies['vote_average'].notnull())][['title','year','vote_count','vote_average','popularity','genres']]\n",
    "top_movies3['vote_count']=top_movies3['vote_count'].astype('int')\n",
    "top_movies3['vote_average']=top_movies3['vote_average'].astype('int')\n",
    "top_movies3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_rating(x):\n",
    "    v=x['vote_count']\n",
    "    R=x['vote_average']\n",
    "    return (v/(v+m)*R)+(m/(v+m)*C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies3['weight_rate']=top_movies3.apply(weighted_rating,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies3=top_movies3.sort_values('weight_rate', ascending=False).head(10)\n",
    "top_movies3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre = romance\n",
    "genre_TM = top_movies.apply(lambda x: pd.Series(x['genres']),axis=1).stack().reset_index(level=1,drop=True)\n",
    "genre_TM.name='genre'\n",
    "genre_top_movies = top_movies.drop('genres',axis=1).join(genre_TM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_top_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chart(genre,percentile=0.85):\n",
    "    df=genre_top_movies[genre_top_movies['genre']==genre]\n",
    "    vote_counts=df[df['vote_count'].notnull()]['vote_count'].astype('int')\n",
    "    vote_averages=df[df['vote_average'].notnull()]['vote_average'].astype('int')\n",
    "    C=vote_averages.mean()\n",
    "    m=vote_counts.quantile(percentile)\n",
    "    \n",
    "    qualified=df[(df['vote_count']>=m) & (df['vote_count'].notnull()) & (df['vote_average'].notnull())][['title','year','vote_count','vote_average','popularity','genres']]\n",
    "    qualified['vote_count']=qualified['vote_count'].astype('int')\n",
    "    qualified['vote_average']=qualified['vote_average'].astype('int')\n",
    "    \n",
    "    qualified['wr']=qualified.apply(lambda x: (x['vote_count']/(x['vote_count'])))\n",
    "    qualified=qualified.sort_values('wr',ascending=False).head(250)\n",
    "    \n",
    "    return qualified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see our method in action by displaying the Top 15 Romance Movies.  \n",
    "(Romance almost didn't feature at all in our Generic Top Chart despite being one of the most popular movie genres)\n",
    "\n",
    "## Top Genres Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_chart('Animation').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_chart('Family').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_chart('Action').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_small = pd.read_csv(\"Dataset/links_small.csv\")\n",
    "links_small = links_small[links_small['tmdbId'].notnull()]['tmdbId'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies = top_movies.drop([19730,29503,35587])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check EDA Notebook for how and why I got these indices\n",
    "top_movies['id']=top_movies['id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies4=top_movies[top_movies['id'].isin(links_small)]\n",
    "top_movies4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have **9099** movies avaiable in our small movies metadata dataset which is 5 times smaller than our original dataset of 45000 movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Description Based Recommender\n",
    "\n",
    "Lets us first try to build a recommender using movies descriptions and taglines. We do not have a quantitative metric to judge our machine's performance so this will have to be done quantatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies4['tagline']=top_movies4['tagline'].fillna('')\n",
    "top_movies4['description']=top_movies4['overview']+top_movies4['tagline']\n",
    "top_movies4['description']=top_movies4['description'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=TfidfVectorizer(analyzer='word',ngram_range=(1,2),min_df=0,stop_words='end')\n",
    "tfidf_matrix=tf.fit_transform(top_movies4['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cosine Similarity**\n",
    "\n",
    "We will be using the cosine similarity to calculate a numeric quantity that denotes the simlarity between two movies. Mathematically, it is defined as follows :\n",
    "\n",
    "$$cosine(x,y)=/fact{}\n",
    "\n",
    "Since we have used the TF-IDF Vectorize, calculating the Dot Product will directly give us the Cosine Similarity Score. Therefore, we will use sklearn's **linear_kernel** instead of cosine_similarities sice it is muxh faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = linear_kernel(tfidf_matrix,tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a pairwise cosine similarity matrix for all the movies in our dataset. The next step is to write a function that returns the 30 most similar movies based on the cosine similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies4 = top_movies4.reset_index()\n",
    "titles=top_movies4['title']\n",
    "indices=pd.Series(top_movies4.index, index=top_movies4['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation(title):\n",
    "    idx=indices\n",
    "    sim_score=list(enumerate(cosine_sim[idx]))\n",
    "    sim_score=sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_score=sim_score[1:31]\n",
    "    movie_indices=[i[0] for i in sim_score]\n",
    "    return titles.iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're all set. Let us now try and get the top recommendations for a few movies and see how good the recommendations are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendation('GoldenEye').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendation('The Apartment').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendation('The Godfather').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendation('The Dark Knight').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "\n",
    "Our content based engine suffers from some severe limitaions. It is only capable of suggesting movies which are close to a certain movie. That is, it is not capable of capturing tastes and providing recommendations.\n",
    "\n",
    "Also, the engine that we built is not really personal in that it doesn't capture the personal tastes and biases of a user. Anyone quering our engine for recommendations based on a movie will recieve the same recommendations for that movie, regardless of who he/she is\n",
    "\n",
    "Therefore, in the section, we will use a technique called **Collaborative Filtering** to make recommendations to Movie Watchers. It is based on the ideas that users similar to a me can be used to predict how much I will like a particular product or service those users have used/experienced but I have not\n",
    "\n",
    "We will notbe implementing collaborative Filtering from scartch. Instead We will use the **Surprise** Library that used extreamly powerfull algorithms like **Singular Value Decomposition (SVD)** to minimise RMSE and give great recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader=Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.read_\n",
    "rating.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
